% CREATED BY DAVID FRISK, 2016
\chapter{Introduction}
Machine learning is one of the hot technologies today as it is being used to solve complex problems that would otherwise be very hard or costly to solve with traditional methods.\\The use of commodity hardware is not the most effective and efficient way to execute Machine Learning, so the goal is to satisfy the required demands for different Machine-Learning models but at lower cost and energy consumption in order to be deployed also on mobile devices.
As it is very well-known, hardware accelerators are capable, if designed correctly, of delivering a lot of improvements in terms of the latency but also in terms of energy efficiency. Thus, in order to obtain the best solution in every metric a hardware-software co-design is needed, requiring to the hardware designer a basic knowledge of machine learning algorithms.\\\\
The goal is to develop a hardware accelerator from scratch, which implements a tensor-based convolution. Exploiting a non Von Neumann architecture and reuse of weights reduces the CPU workload and boost the models' performance. The use of different arithmetic data type can drastically reduce the computations without reducing the final accuracy of the Neural Network. From a hardware perspective, the use of different arithmetic precision, such as the use of integer operations instead of floating-point operations, can lead to benefits in terms of area, energy consumption and latency.
